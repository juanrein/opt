{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-driven optimization and decision making - Assignment 2\n",
    "Juha Reinikainen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import qmc\n",
    "from desdeo_problem import variable_builder, \\\n",
    "    ScalarConstraint, MOProblem, ScalarObjective\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor, kernels\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "# from sklearn import preprocessing\n",
    "import warnings\n",
    "#hide gridsearchcv convergence warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "seed = 1\n",
    "n_folds = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the problem\n",
    "# https://www.mathworks.com/help/gads/multiobjective-optimization-welded-beam.html\n",
    "def F1(x):\n",
    "    \"\"\"\n",
    "    minimize the fabrication cost of the beam\n",
    "    \"\"\"\n",
    "    return 1.10471 * x[:, 0]**2 * x[:, 1] + 0.04811 * x[:, 2] * x[:, 3] * (14.0 + x[:, 1])\n",
    "\n",
    "\n",
    "P = 6000.0  # max supported load of the beam\n",
    "L = 14.0  # length of part\n",
    "\n",
    "\n",
    "def F2(x):\n",
    "    \"\"\"\n",
    "    Minimize the deflection of the beam\n",
    "    \"\"\"\n",
    "    C = (4*(14**3))/(30*10**6)\n",
    "    return (P / (x[:, 3] * x[:, 2]**3)) * C\n",
    "\n",
    "\n",
    "objectives = [\n",
    "    ScalarObjective(\"cost\", F1, maximize=False),\n",
    "    ScalarObjective(\"deflection\", F2, maximize=False)\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "Welded beam design problem\n",
    "x[0] the thickness of the welds\n",
    "x[1] the length of the welds\n",
    "x[2] the height of the beam\n",
    "x[3] the width of the beam\n",
    "\"\"\"\n",
    "var_names = [\"thickness\", \"length\", \"height\", \"width\"]\n",
    "lb = [0.125, 0.1, 0.1, 0.125]\n",
    "ub = [5.0, 10.0, 10.0, 5.0]\n",
    "initial_values = [0.125, 0.1, 0.1, 0.125]\n",
    "variables = variable_builder(var_names, initial_values, lb, ub)\n",
    "\n",
    "\n",
    "def shear_stress(x, y):\n",
    "    r1 = 1 / np.sqrt(2 * x[:, 0] * x[:, 1])\n",
    "    R = np.sqrt(x[:, 1]**2 + (x[:, 0] + x[:, 2])**2)\n",
    "    r2 = ((L + x[:, 1]/2) * R) / np.sqrt(2 * x[:, 0] *\n",
    "                                         x[:, 2] * ((x[:, 1]**2)/3 + (x[:, 0] + x[:, 2])**2))\n",
    "    r = P * np.sqrt(r1**2 + r2**2 + (2*r1*r2*x[:, 1])/R)\n",
    "    return 13600 - r\n",
    "\n",
    "\n",
    "constraints = [\n",
    "    ScalarConstraint(\"thickness\", 4, 2, lambda x, y: x[:, 3] - x[:, 0]),\n",
    "    ScalarConstraint(\"shear stress\", 4, 2, shear_stress),\n",
    "    ScalarConstraint(\"normal stress\", 4, 2, lambda x,\n",
    "                     y: 30000 - P * (6 * L)/(x[:, 3]*x[:, 2]**2)),\n",
    "    ScalarConstraint(\"buckling load\", 4, 2, lambda x, y: (\n",
    "        64746.022 * (1-0.0282346*x[:, 2])*x[:, 2]*x[:, 3]**3) - 6000),\n",
    "]\n",
    "\n",
    "prob = MOProblem(objectives=objectives, variables=variables,\n",
    "                 constraints=constraints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15176185 0.15909181 0.13072661 0.13322651] \n",
      " [4.96363502 9.90438302 9.97704191 4.99043053]\n",
      "[6.5883435e-01 5.6626839e-04] [219.66098571 503.10180463]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate data\n",
    "\"\"\"\n",
    "\n",
    "# Generate samples and scale them based on the box constraints\n",
    "# and minmax scaling because the objective function values have large range\n",
    "lhs = qmc.LatinHypercube(4, seed=seed)\n",
    "X = lhs.random(100)\n",
    "X = qmc.scale(X, lb, ub)\n",
    "res = prob.evaluate(X)\n",
    "y = res.objectives\n",
    "# y = preprocessing.MinMaxScaler().fit_transform(y)\n",
    "y1 = y[:, 0]\n",
    "y2 = y[:, 1]\n",
    "\n",
    "# test samples\n",
    "X_test = lhs.random(50)\n",
    "X_test = qmc.scale(X_test, lb, ub)\n",
    "res_test = prob.evaluate(X_test)\n",
    "y_test = res_test.objectives\n",
    "# y_test = preprocessing.MinMaxScaler().fit_transform(y_test)\n",
    "y1_test = y_test[:, 0]\n",
    "y2_test = y_test[:, 1]\n",
    "\n",
    "print(X.min(axis=0), \"\\n\", X.max(axis=0))\n",
    "print(y.min(axis=0), y.max(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective 1\n",
      "r2 [0.88131703 0.80597788 0.92493396 0.91108308 0.91605465]\n",
      "mean 0.887873318826464\n",
      "var 0.0018912439550861262\n",
      "rmse [16.85917701 18.80036625 13.56853671 13.09881632 14.57951492]\n",
      "mean 15.381282241657715\n",
      "var 4.6025672500174695\n",
      "objective 2\n",
      "r2 [  0.65998944   0.05645192  -1.51788178 -19.06785278   0.87095429]\n",
      "mean -3.7996677835413406\n",
      "var 58.979386573927876\n",
      "rmse [  1.01990603 106.50289908   9.19476714  30.24456323   0.13067523]\n",
      "mean 29.41856214413365\n",
      "var 1603.1886305197927\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cross validate random forest\n",
    "objective 2 only depends on the two last variables so only\n",
    "use those for fitting for all y2 models\n",
    "\"\"\"\n",
    "\n",
    "randomForestRegressor_y1 = RandomForestRegressor(random_state=seed)\n",
    "randomForestRegressor_y2 = RandomForestRegressor(random_state=seed)\n",
    "randomForestRegressor_y1.fit(X,y1)\n",
    "randomForestRegressor_y2.fit(X[:,2:],y2)\n",
    "\n",
    "scoring = [\"r2\", \"neg_root_mean_squared_error\"]\n",
    "\n",
    "scores_y1 = cross_validate(randomForestRegressor_y1,\n",
    "                           X, y1, scoring=scoring, cv=n_folds)\n",
    "scores_y2 = cross_validate(randomForestRegressor_y2,\n",
    "                           X[:,2:], y2, scoring=scoring, cv=n_folds)\n",
    "print(\"objective 1\")\n",
    "print(\"r2\", scores_y1[\"test_r2\"])\n",
    "print(\"mean\", scores_y1[\"test_r2\"].mean())\n",
    "print(\"var\", scores_y1[\"test_r2\"].var())\n",
    "print(\"rmse\", -scores_y1[\"test_neg_root_mean_squared_error\"])\n",
    "print(\"mean\", (-scores_y1[\"test_neg_root_mean_squared_error\"]).mean())\n",
    "print(\"var\", (-scores_y1[\"test_neg_root_mean_squared_error\"]).var())\n",
    "\n",
    "print(\"objective 2\")\n",
    "print(\"r2\", scores_y2[\"test_r2\"]) \n",
    "print(\"mean\", scores_y2[\"test_r2\"].mean()) \n",
    "print(\"var\", scores_y2[\"test_r2\"].var())\n",
    "print(\"rmse\", -scores_y2[\"test_neg_root_mean_squared_error\"])\n",
    "print(\"mean\", (-scores_y2[\"test_neg_root_mean_squared_error\"]).mean())\n",
    "print(\"var\", (-scores_y2[\"test_neg_root_mean_squared_error\"]).var())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-10 5.62341325e-08 3.16227766e-05 1.77827941e-02\n",
      " 1.00000000e+01]\n",
      "GaussianProcessRegressor(alpha=3.1622776601683795e-05,\n",
      "                         kernel=ExpSineSquared(length_scale=1, periodicity=1),\n",
      "                         n_restarts_optimizer=5, random_state=1)\n",
      "GaussianProcessRegressor(alpha=10.0,\n",
      "                         kernel=ExpSineSquared(length_scale=1, periodicity=1),\n",
      "                         n_restarts_optimizer=5, random_state=1)\n",
      "objective 1\n",
      "r2 [0.99681554 0.99310156 0.99642601 0.99109819 0.9827452 ]\n",
      "mean 0.9920372994513402\n",
      "var 2.608998026379606e-05\n",
      "rmse [2.76159753 3.54499953 2.96065663 4.14456525 6.60997263]\n",
      "mean 4.004358312015205\n",
      "var 1.930732399940655\n",
      "objective 2\n",
      "r2 [-0.07988484 -0.03819489  0.86959511 -0.16648495  0.06763787]\n",
      "mean 0.1305336594683512\n",
      "var 0.14222660516253888\n",
      "rmse [  1.81761828 111.7168946    2.0925219    7.29182831   0.35124795]\n",
      "mean 24.654022207251753\n",
      "var 1900.5074006571908\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "tune hyperparameters and crossvalidate Kriging\n",
    "\"\"\"\n",
    "\n",
    "parameters = {\n",
    "    \"alpha\": np.logspace(-10, 1, 5),\n",
    "    \"kernel\": [\n",
    "        kernels.RBF(),\n",
    "        kernels.ExpSineSquared(),\n",
    "        kernels.DotProduct(),\n",
    "        kernels.RationalQuadratic(),\n",
    "    ],\n",
    "    # \"normalize_y\": [False, True]\n",
    "}\n",
    "print(parameters[\"alpha\"])\n",
    "\n",
    "gaussianProcessRegressor_y1 = \\\n",
    "    GridSearchCV(GaussianProcessRegressor(\n",
    "                                          n_restarts_optimizer=5, \n",
    "                                          random_state=seed), parameters, cv=n_folds)\n",
    "gaussianProcessRegressor_y2 = \\\n",
    "    GridSearchCV(GaussianProcessRegressor(\n",
    "                                          n_restarts_optimizer=5, \n",
    "                                          random_state=seed), parameters, cv=n_folds)\n",
    "# fit best parameters\n",
    "gaussianProcessRegressor_y1.fit(X, y1)\n",
    "gaussianProcessRegressor_y1 = gaussianProcessRegressor_y1.best_estimator_\n",
    "gaussianProcessRegressor_y2.fit(X[:,2:], y2)\n",
    "gaussianProcessRegressor_y2 = gaussianProcessRegressor_y2.best_estimator_\n",
    "print(gaussianProcessRegressor_y1)\n",
    "print(gaussianProcessRegressor_y2)\n",
    "\n",
    "# 5-folds\n",
    "scores_y1 = cross_validate(gaussianProcessRegressor_y1,\n",
    "                           X, y1, scoring=scoring, cv=n_folds)\n",
    "scores_y2 = cross_validate(gaussianProcessRegressor_y2,\n",
    "                           X[:,2:], y2, scoring=scoring, cv=n_folds)\n",
    "\n",
    "print(\"objective 1\")\n",
    "print(\"r2\", scores_y1[\"test_r2\"])\n",
    "print(\"mean\", scores_y1[\"test_r2\"].mean())\n",
    "print(\"var\", scores_y1[\"test_r2\"].var())\n",
    "print(\"rmse\", -scores_y1[\"test_neg_root_mean_squared_error\"])\n",
    "print(\"mean\", (-scores_y1[\"test_neg_root_mean_squared_error\"]).mean())\n",
    "print(\"var\", (-scores_y1[\"test_neg_root_mean_squared_error\"]).var())\n",
    "\n",
    "print(\"objective 2\")\n",
    "print(\"r2\", scores_y2[\"test_r2\"]) \n",
    "print(\"mean\", scores_y2[\"test_r2\"].mean()) \n",
    "print(\"var\", scores_y2[\"test_r2\"].var())\n",
    "print(\"rmse\", -scores_y2[\"test_neg_root_mean_squared_error\"])\n",
    "print(\"mean\", (-scores_y2[\"test_neg_root_mean_squared_error\"]).mean())\n",
    "print(\"var\", (-scores_y2[\"test_neg_root_mean_squared_error\"]).var())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest test\n",
      "r2 objective 1 0.9451871125660081\n",
      "rmse objective 1 11.58173974486011\n",
      "r2 objective 2 -0.0390106962515091\n",
      "rmse objective 2 23.882504146127694\n",
      "kriging test\n",
      "r2 objective 1 0.9977810759053293\n",
      "rmse objective 1 2.3302562657945987\n",
      "r2 objective 2 0.005122087168357492\n",
      "rmse objective 2 23.3697866280749\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compute metrics for both models on test data\n",
    "\"\"\"\n",
    "y1_pred_forest = randomForestRegressor_y1.predict(X_test)\n",
    "y2_pred_forest = randomForestRegressor_y2.predict(X_test[:,2:])\n",
    "print(\"random forest test\")\n",
    "print(\"r2 objective 1\", r2_score(y1_test, y1_pred_forest))\n",
    "print(\"rmse objective 1\", mean_squared_error(\n",
    "    y1_test, y1_pred_forest, squared=False))\n",
    "print(\"r2 objective 2\", r2_score(y2_test, y2_pred_forest))\n",
    "print(\"rmse objective 2\", mean_squared_error(\n",
    "    y2_test, y2_pred_forest, squared=False))\n",
    "\n",
    "y1_pred_kriging = gaussianProcessRegressor_y1.predict(X_test)\n",
    "y2_pred_kriging = gaussianProcessRegressor_y2.predict(X_test[:,2:])\n",
    "print(\"kriging test\")\n",
    "print(\"r2 objective 1\", r2_score(y1_test, y1_pred_kriging))\n",
    "print(\"rmse objective 1\", mean_squared_error(\n",
    "    y1_test, y1_pred_kriging, squared=False))\n",
    "print(\"r2 objective 2\", r2_score(y2_test, y2_pred_kriging))\n",
    "print(\"rmse objective 2\", mean_squared_error(\n",
    "    y2_test, y2_pred_kriging, squared=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For k-fold CV the cell value contains mean and variance computed from invidual values of r-squared and rmse on each fold.\n",
    "\n",
    "|  | | Objective 1 | | Objective 2 | |\n",
    "| ---- | ---- | -- | -- | --       | -- |\n",
    "|  | | Kriging | Random forest | Kriging | Random forest |\n",
    "| k-fold CV | R-squared | 0.99 (2.6-05) | 0.89 (0.002) | 0.13 (0.142)| -3.80 (58.98) |\n",
    "|  | RMSE |  4.0 (1.93) | 15.4 (4.60) | 24.7 (1900.51) |29.4 (1603.19) |\n",
    "| Test | R-squared | 1.00 | 0.95 | 0.005 | -0.039 |\n",
    "|  | RMSE | 2.3 | 11.6 | 23.4 | 23.9 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the r-squared and rmse scores on training set, Kriging performed significantly better reaching almost r-squared score of 1 and it has smaller rmse value so it should be used as surrogate for objective 1. Both models performed poorly on objective 2 but once again Kriging was a bit better. Random forest could probably perform better with some hyperparameter tuning.\n",
    "\n",
    "On the test set the models behaved similarly to the training set.  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d67f4bcf1604c44bf18ec22d97f283eada189abc7af111a58bd3017a8979d250"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
