{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-driven optimization and decision making - Assignment 3\n",
    "Juha Reinikainen\n",
    "\n",
    "Use EI and the mean prediction to solve any single objective benchmark problem (e.g.\n",
    "Ackley, Rosenblock, sphere etc.) with any single objective optimizer (preferably GA). Set\n",
    "max exact function evaluations to 50 (start with 50 design points). Was the solutions\n",
    "found by EI better? (you can implement EI is you wish to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pymoo.factory import get_problem\n",
    "from scipy.stats import qmc\n",
    "from pymoo.algorithms.soo.nonconvex.ga import GA\n",
    "from pymoo.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "import problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_datadriven_rosenbrock_optimization(use_EI = False):\n",
    "    \"\"\"\n",
    "    find minimum of rosenbrock\n",
    "    use_EI use expected improvement strategy to choose point to evaluate\n",
    "    otherwise mean approximation is used\n",
    "    \"\"\"\n",
    "    seed = 1\n",
    "    max_eval = 50\n",
    "    # rosenbrock = get_problem(\"ackley\", n_var=1, a=20, b=1/5, c=2 * np.pi)\n",
    "    #x = 1, f = 0\n",
    "    rosenbrock = get_problem(\"rosenbrock\", n_var=2)\n",
    "    surrogate = GaussianProcessRegressor()\n",
    "    \n",
    "    optimizer = GA(pop_size=100)\n",
    "    optimizer_acquisition = GA(pop_size=100)\n",
    "\n",
    "    #generate initial sample\n",
    "    lhs = qmc.LatinHypercube(rosenbrock.n_var, seed=seed)\n",
    "    X = lhs.random(50)\n",
    "    X = qmc.scale(X, rosenbrock.xl, rosenbrock.xu)\n",
    "    y = rosenbrock.evaluate(X)\n",
    "\n",
    "    #Build surrogates with initial data\n",
    "    surrogate.fit(X, y)\n",
    "\n",
    "    history = {\n",
    "        \"X\": [],\n",
    "        \"y\": []\n",
    "    }\n",
    "\n",
    "    surrogateProblem = problems.Surrogate(rosenbrock, surrogate)\n",
    "    for _ in range(max_eval):\n",
    "        #find optimum of surrogate\n",
    "        best = minimize(surrogateProblem, optimizer, (\"n_gen\", 10), seed=seed)\n",
    "        history[\"X\"].append(best.X)\n",
    "        history[\"y\"].append(best.F)\n",
    "\n",
    "        #choose which point to evaluate\n",
    "        if use_EI:\n",
    "            #construct EI rosenbrock with found optimum\n",
    "            ei = problems.ExpectedImprovement(rosenbrock, surrogate, best.F)\n",
    "\n",
    "            #optimize considering expected improvement\n",
    "            res = minimize(ei, optimizer_acquisition, (\"n_gen\", 10), seed=seed)\n",
    "            x_t = res.X\n",
    "        else:\n",
    "            x_t = best.X\n",
    "\n",
    "        #print(res.X, -res.F, end = \", \")\n",
    "        #evaluate the chosen point with real function\n",
    "        y_t = rosenbrock.evaluate(x_t)\n",
    "\n",
    "        #add newly evaluated to data\n",
    "        X = np.append(X, [x_t], axis=0)\n",
    "        y = np.append(y, [y_t], axis=0)\n",
    "        #Rebuild the surrogates with the new data\n",
    "        surrogate.fit(X, y)\n",
    "\n",
    "    # do final optimization\n",
    "    best = minimize(surrogateProblem, optimizer, (\"n_gen\", 10), seed=seed)\n",
    "    history[\"X\"].append(best.X)\n",
    "    history[\"y\"].append(best.F)\n",
    "\n",
    "    return best.X, best.F, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,y1, hist1 = online_datadriven_rosenbrock_optimization(False)\n",
    "x2,y2, hist2 = online_datadriven_rosenbrock_optimization(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean [0.97923458 0.95661389] [0.00099707] 0.04809944780227716\n",
      "EI   [1.05692369 1.1119617 ] [0.03909372] 0.12560146341718723\n"
     ]
    }
   ],
   "source": [
    "x_true = np.ones(x1.shape)\n",
    "y_true = np.zeros(y1.shape)\n",
    "print(\"mean\", x1,y1, np.linalg.norm(x_true - x1))\n",
    "print(\"EI  \", x2,y2, np.linalg.norm(x_true - x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean prediction is a little better than expected improvement on 2 dimensional Rosenbrock function. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d67f4bcf1604c44bf18ec22d97f283eada189abc7af111a58bd3017a8979d250"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
